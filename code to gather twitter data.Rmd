---
title: "getting the twitter data"
output:
  pdf_document: default
  html_document: default
authors: Sammy Salustri and Yagmur Idil Ozdemir
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(twitteR)
library(tm)
library(readxl)
library(dplyr)
library(readr)
#install.packages("devtools")
library("devtools")
#install_github("cran/SentimentAnalysis")
library(SentimentAnalysis)
library(tidytext)
library (reshape2)
install_github("trinker/lexicon") 
library(lexicon) 

library(SnowballC)
library(wordcloud)
library(RColorBrewer)


```

##Get Access to twitter Data: We created credentials for "Politicians Language Analysis." App ID is 15958126.  

```{r}

#consumer_key <- ""
#consumer_secret<- ""
#access_token <- ""
#access_secret <- ""
#github got mad at me for posting these when I pushed this file. I have the actual numbers on my computer.

setup_twitter_oauth(consumer_key ,consumer_secret,access_token ,access_secret)
```

## Create dataset containing all tweets of all politicians and the times they were created. For preliminary testing to make sure all twitter accounts are accessible and for run-time concerns, we only take in one tweet per politician. We will change this. 

```{r }

politicians_df<-read_xlsx("politicians.xlsx")
handles<-politicians_df$twitter_handle


get_tweets<- function(user) {
  user_data<-userTimeline(user, n=5, includeRts=FALSE)
  result_df<- twListToDF(user_data) %>% select(text, created,screenName)
  return(result_df)
}

all_data<-rbind(lapply(handles, FUN=get_tweets))
results<-do.call("rbind", all_data)

```

## Return the frequency of the words that are parsed from each tweet, returned as a list. We clean the data from any punctuation, turn words to lower case and exclude stopwords. 

```{r}

#example user
user<- "ChrisCoons"

user_text <- results %>% filter(screenName == user) %>% select(text)

freq <- termFreq(user_text$text, control = list(removePunctuation = TRUE, tolower = TRUE, stopwords = TRUE)) 

freq <- as.data.frame(melt(as.matrix(freq), varnames = c("word", "some"))) %>% select(-some)

freq$word <- as.character(freq$word)

freq_for_trait <- freq
freq <- freq %>% arrange(desc(value)) %>% head(n=10)

#x <- do.call("c", (mapply(rep, freq_for_trait$word, freq_for_trait$value))) 
#x <- as.data.frame(x)
#freq_for_trait <- x$x %>% as.character() %>% as.data.frame(freq_for_trait)
```

#word frequency clouds
```{r}
#use tm packange

set.seed(1234)
wordcloud(words = freq$word, freq = freq$value, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

```


##Get csv files for running personality test on freq words
```{r warning=FALSE, message=FALSE}
#make library five personality, with one column referring to trait 

library_conscientiousness <- read_csv('http://wwbp.org/downloads/public_data/C.top100.1to3grams.gender_age_controlled.rmatrix.csv') %>% mutate(trait = "conscientiousness") %>% select(-con)
library_openness <- read_csv('http://wwbp.org/downloads/public_data/O.top100.1to3grams.gender_age_controlled.rmatrix.csv') %>% mutate(trait = "openness") %>% select(-ope)
library_agreeableness <- read_csv('http://wwbp.org/downloads/public_data/A.top100.1to3grams.gender_age_controlled.rmatrix.csv') %>% mutate(trait = "agreeableness") %>% select(-agr)
library_extraversion <- read_csv('http://wwbp.org/downloads/public_data/E.top100.1to3grams.gender_age_controlled.rmatrix.csv') %>% mutate(trait = "extraversion") %>% select(-ext)
library_neuroticism  <- read_csv('http://wwbp.org/downloads/public_data/N.top100.1to3grams.gender_age_controlled.rmatrix.csv') %>% mutate(trait = "neuroticism") %>% select(-neu)

library_fivepersonality <- rbind(library_agreeableness,library_conscientiousness,library_extraversion, library_neuroticism, library_openness)

inner_join(library_fivepersonality, freq_for_trait, by = c("X1" = "word"))

find_personality <- function (word){
  word_found<- library_fivepersonality %>% filter(X1 == word) %>% arrange(p) %>% head(n=1)
  
  return(c(word_found$trait, word_found$X1))
}
fivepersonality_data <- sapply(freq_for_trait$word, FUN = find_personality)
fivepersonality_data <- data.frame(t(fivepersonality_data))
#not all words are in this dictionary
```


##Get sentiment libraries in R for word/sentence sentiment : positive/negative ex.
```{r}

#str(sentiments)

find_sentiments <- function (our_word){
  word_found<- sentiments %>% filter( word == our_word)
   if (!is.na(word_found))
  {return(word_found)}
}
sentiment_data <- sapply(freq$word, FUN = find_sentiments)
sentiment_data <- data.frame(t(sentiment_data))


sentiment<-analyzeSentiment(user_text$text[1])
convertToDirection(sentiment)

#examples -- proof of concept
#sentiment <- analyzeSentiment("I really hate doing screeening on zebrafish.")
#sentiment$SentimentQDAP
#[1] -0.25
#sentiment <- analyzeSentiment("Knowing I go back home in 2 weeks makes studying easier")
# sentiment$SentimentQDAP
#[1] 0.1428571
# sentiment <- analyzeSentiment("I cannot believe I won that lottery. Dreams do come true!")
# sentiment$SentimentQDAP
#[1] 0.5
#analyzeSentiment() does wordcount, uncertainity also
#there are multiple dictionaries inside, this is QDAP scores. 
```

##This has subjectivity : https://www.r-bloggers.com/slightly-more-than-basic-sentiment-analysis/

```{r}

key_regressive_imagery_our <- key_regressive_imagery %>% mutate(regex = gsub("[^0-9A-Za-z///' ]","'" , regex ,ignore.case = TRUE)) %>% mutate(regex = sub("\\'b$", "", regex)) %>% mutate(regex = sub("\\'", "", regex)) %>% mutate(regex = sub("^b", "", regex))

find_imagery <- function (our_word){
  word_found<- key_regressive_imagery_our %>% filter( regex == our_word)
  #if (!is.na(word_found))
  return(word_found)
}
imagery_data <- sapply(freq$word, FUN = find_imagery)
imagery_data <- data.frame(t(imagery_data))


```

